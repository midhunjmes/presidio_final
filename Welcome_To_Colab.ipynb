{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/midhunjmes/presidio_final/blob/main/Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install openpyxl\n",
        "!pip install presidio_analyzer\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "gP5BWVM0NAh1",
        "outputId": "2648703c-d14c-40c3-9e37-c9ceed7f9e20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Collecting presidio_analyzer\n",
            "  Downloading presidio_analyzer-2.2.358-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting phonenumbers<9.0.0,>=8.12 (from presidio_analyzer)\n",
            "  Downloading phonenumbers-8.13.55-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (6.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (2024.11.6)\n",
            "Requirement already satisfied: spacy!=3.7.0,<4.0.0,>=3.4.4 in /usr/local/lib/python3.11/dist-packages (from presidio_analyzer) (3.8.4)\n",
            "Collecting tldextract (from presidio_analyzer)\n",
            "  Downloading tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.5.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio_analyzer) (3.10)\n",
            "Collecting requests-file>=1.4 (from tldextract->presidio_analyzer)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio_analyzer) (3.18.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer) (0.1.2)\n",
            "Downloading presidio_analyzer-2.2.358-py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading phonenumbers-8.13.55-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: phonenumbers, requests-file, tldextract, presidio_analyzer\n",
            "Successfully installed phonenumbers-8.13.55 presidio_analyzer-2.2.358 requests-file-2.1.0 tldextract-5.1.3\n",
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from presidio_analyzer import AnalyzerEngine\n",
        "\n",
        "# analyzer = AnalyzerEngine()\n",
        "# for recognizer in analyzer.get_recognizers():\n",
        "#     print(recognizer.supported_entities)"
      ],
      "metadata": {
        "id": "clvNKuSWc9QN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "import openpyxl\n",
        "import json\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "analyzer = AnalyzerEngine()\n",
        "mapping={}\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------------------------------------------------------\n",
        "#function to find out the noun values dominating columns considering it will be a sensitive data if there is so many nouns\n",
        "#------------------------------------------------------------------------------------------------------------------------------\n",
        "def detect_noun(file_path):\n",
        "    if file_path.endswith(\".csv\"):\n",
        "        df = pd.read_csv(file_path, engine=\"python\")\n",
        "    elif file_path.endswith((\".xls\", \".xlsx\")):\n",
        "        df = pd.read_excel(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Please provide a CSV or Excel file.\")\n",
        "\n",
        "    sensitive = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype in ['int64', 'float64']:\n",
        "            continue  # Skip purely numeric columns\n",
        "\n",
        "        text_samples = df[col].astype(str).head(5)  # Take first 5 values\n",
        "        noun_count = 0\n",
        "        total_count = 0\n",
        "\n",
        "        for value in text_samples:\n",
        "            if \"%\" in value or value.replace(\".\", \"\").isdigit():\n",
        "                continue  # Skip percentage or number-like values\n",
        "\n",
        "            doc = nlp(value)\n",
        "            for token in doc:\n",
        "                if token.pos_ in ['NOUN', 'PROPN']:\n",
        "                    noun_count += 1\n",
        "                total_count += 1\n",
        "\n",
        "        # Mark column as sensitive only if a significant portion are nouns\n",
        "        if total_count > 0 and (noun_count / total_count) > 0.2:\n",
        "            sensitive.append(col)\n",
        "\n",
        "    return sensitive\n",
        "\n",
        "\n",
        "#------------------------------------------------------------------------------------------\n",
        "#finding out the descriptive data columns which may have sensitive data in the form of text\n",
        "#------------------------------------------------------------------------------------------\n",
        "def descriptive_columns(file_path):\n",
        "    # Define keywords to filter out\n",
        "    keywords = [\"description\", \"remarks\", \"notes\", \"comments\", \"observations\", \"details\", \"summary\", \"explanation\",\n",
        "    \"reviews\", \"feedback\", \"testimonials\", \"opinions\", \"assessment\", \"suggestions\", \"experience\",\n",
        "    \"incident_report\", \"case_notes\", \"audit_notes\", \"findings\", \"status_update\", \"history\", \"progress_report\",\n",
        "    \"additional_info\", \"clarifications\", \"justification\", \"annotations\", \"excerpts\", \"statement\", \"explanation_text\"]\n",
        "\n",
        "    # Ensure columns are properly loaded from CSV/Excel\n",
        "    if file_path.endswith(\".csv\"):\n",
        "        df = pd.read_csv(file_path, nrows=1)  # Read only header\n",
        "    elif file_path.endswith((\".xls\", \".xlsx\")):\n",
        "        df = pd.read_excel(file_path, nrows=1, engine=\"openpyxl\")  # Read only header\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Please provide a CSV or Excel file.\")\n",
        "\n",
        "    # Get actual column names\n",
        "    all_columns = df.columns.tolist()\n",
        "\n",
        "\n",
        "    des=[col for col in all_columns if any(re.search(keyword, col, re.IGNORECASE) for keyword in keywords)]\n",
        "    return des\n",
        "\n",
        "#-----------------------------------------------------------------\n",
        "#anonymizing descriptive values\n",
        "#-----------------------------------------------------------------\n",
        "def detect_noun_desc(text):\n",
        "    doc = nlp(text)\n",
        "    modified_text=[]\n",
        "    for token in doc:\n",
        "        if token.pos_ in ['PROPN']:\n",
        "            modified_text.append(\"<sensitive>\")\n",
        "        else:\n",
        "            modified_text.append(token.text)\n",
        "    text=\" \".join(modified_text)\n",
        "    return text\n",
        "\n",
        "\n",
        "#------------------------------------------------------------------\n",
        "#function for detecting numerical sensitive\n",
        "#------------------------------------------------------------------\n",
        "def detect_sensitive_numerical(file_path,sensitive):\n",
        "    if file_path.endswith(\".csv\"):\n",
        "        df = pd.read_csv(file_path, engine=\"python\")\n",
        "    elif file_path.endswith((\".xls\", \".xlsx\")):\n",
        "        df = pd.read_excel(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Please provide a CSV or Excel file.\")\n",
        "\n",
        "    sensitive_columns = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col not in sensitive:\n",
        "          text_samples = df[col].astype(str).head(5)  # Convert first 5 values to string\n",
        "\n",
        "          for value in text_samples:\n",
        "              if pd.notna(value) and value.strip():\n",
        "                  results = analyzer.analyze(text=value, language=\"en\")\n",
        "\n",
        "                  for result in results:\n",
        "                      # print(result,result.entity_type)\n",
        "                      if result.entity_type in [\"PHONE_NUMBER\", \"CREDIT_CARD\", \"IBAN\", \"US_SSN\",\"EMAIL\"]:\n",
        "                          sensitive_columns.append(col)\n",
        "                          break  # If any value in the column is sensitive, mark the whole column\n",
        "\n",
        "    return list(set(sensitive_columns))\n",
        "#-------------------------------------------------------------------\n",
        "#function to anonymize a excel file\n",
        "#-------------------------------------------------------------------\n",
        "def excel_an(input_file, output_file):\n",
        "    df = pd.read_excel(input_file)  # Read as string for safety\n",
        "\n",
        "    sensitive_old = detect_noun(input_file)\n",
        "    desc = descriptive_columns(input_file)\n",
        "    sensitive = list(set(sensitive_old) - set(desc))\n",
        "    num_sensitive=detect_sensitive_numerical(input_file,sensitive_old)\n",
        "    sensitive=list(set(sensitive)+set(num_sensitive))\n",
        "\n",
        "    column_counters = {col: 1 for col in df.columns if col in sensitive_old}\n",
        "    column_mappings = {col: {} for col in sensitive}  # Store mappings for each column\n",
        "    mapping = {}\n",
        "\n",
        "    # Anonymize sensitive columns while maintaining consistency\n",
        "    for col in sensitive:\n",
        "        new_values = []\n",
        "        for val in df[col].astype(str):\n",
        "            if pd.notna(val):\n",
        "                if val in column_mappings[col]:\n",
        "                    anonymized_value = column_mappings[col][val]  # Use existing mapping\n",
        "                else:\n",
        "                    anonymized_value = f\"{col}{column_counters[col]}\"\n",
        "                    column_mappings[col][val] = anonymized_value  # Store new mapping\n",
        "                    column_counters[col] += 1  # Increment counter\n",
        "\n",
        "                mapping[anonymized_value] = val\n",
        "                new_values.append(anonymized_value)\n",
        "            else:\n",
        "                new_values.append(val)\n",
        "\n",
        "        df[col] = new_values\n",
        "\n",
        "    # Anonymize descriptive columns\n",
        "    for col in desc:\n",
        "        for idx, val in enumerate(df[col].astype(str)):\n",
        "            if pd.notna(val):\n",
        "                an_values = detect_noun_desc(val)\n",
        "                df.at[idx, col] = an_values\n",
        "                mapping[an_values] = val\n",
        "\n",
        "    df.to_excel(output_file, index=False, sheet_name=\"Anonymized Data\")\n",
        "    print(f\"✅ Anonymized file saved as {output_file}\")\n",
        "\n",
        "    # Save mapping as JSON\n",
        "    with open(\"mappings.json\", \"w\") as f:\n",
        "        json.dump(mapping, f)\n",
        "\n",
        "#------------------------------------------------------\n",
        "#function for de-anonymizing excel data\n",
        "#------------------------------------------------------\n",
        "\n",
        "def excel_dean(input_file, output_file, mapping_file):\n",
        "    print(\"🔄 Loading data...\")\n",
        "\n",
        "    with open(mapping_file, \"r\") as f:\n",
        "        mapping = json.load(f)\n",
        "\n",
        "    df = pd.read_excel(input_file)  # Read as string for safety\n",
        "    mapping_keys = set(mapping.keys())\n",
        "    df = df.applymap(lambda x: mapping[x] if x in mapping_keys else x)\n",
        "    df.to_excel(output_file, index=False, sheet_name=\"De-anonymized Data\")\n",
        "\n",
        "    print(f\"✅ De-anonymized file saved as {output_file}\")\n",
        "\n",
        "#----------------------------------------------------------\n",
        "#function for anonymizing csv data\n",
        "#----------------------------------------------------------\n",
        "def csv_an(input_file, output_file):\n",
        "    df = pd.read_csv(input_file, engine=\"python\")\n",
        "\n",
        "    sensitive_old = detect_noun(input_file)\n",
        "    desc = descriptive_columns(input_file)\n",
        "    sensitive = list(set(sensitive_old) - set(desc))\n",
        "    num_sensitive=detect_sensitive_numerical(input_file,sensitive_old)\n",
        "    sensitive=sensitive+num_sensitive\n",
        "    column_counters = {col: 1 for col in df.columns if col in sensitive}\n",
        "    column_mappings = {col: {} for col in sensitive}  # Store mappings for each column\n",
        "\n",
        "    # Anonymize sensitive columns while maintaining consistency\n",
        "    for col in sensitive:\n",
        "        new_values = []\n",
        "        for val in df[col].astype(str):\n",
        "            if pd.notna(val):\n",
        "                if val in column_mappings[col]:\n",
        "                    anonymized_value = column_mappings[col][val]  # Use existing mapping\n",
        "                else:\n",
        "                    anonymized_value = f\"{col}{column_counters[col]}\"\n",
        "                    column_mappings[col][val] = anonymized_value  # Store new mapping\n",
        "                    column_counters[col] += 1  # Increment counter\n",
        "\n",
        "                mapping[anonymized_value] = val\n",
        "                new_values.append(anonymized_value)\n",
        "            else:\n",
        "                new_values.append(val)\n",
        "\n",
        "        df[col] = new_values\n",
        "\n",
        "    # Anonymize descriptive columns\n",
        "    for col in desc:\n",
        "        for idx, val in enumerate(df[col].astype(str)):\n",
        "            if pd.notna(val):\n",
        "                an_values = detect_noun_desc(val)\n",
        "                df.at[idx, col] = an_values\n",
        "                mapping[an_values] = val\n",
        "\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"✅ Anonymized file saved as {output_file}\")\n",
        "\n",
        "    # Save mapping as JSON\n",
        "    with open(\"mappings.json\", \"w\") as f:\n",
        "        json.dump(mapping, f)\n",
        "\n",
        "#------------------------------------------------------------\n",
        "#function for de anonymizing csv data\n",
        "#------------------------------------------------------------\n",
        "def csv_dean(input_file, output_file, mapping_file):\n",
        "    print(\"🔄 Loading data...\")\n",
        "\n",
        "    with open(mapping_file, \"r\") as f:\n",
        "        mapping = json.load(f)\n",
        "    df = pd.read_csv(input_file, engine=\"python\", dtype=str)  # Read as string for safety\n",
        "    mapping_keys = set(mapping.keys())\n",
        "    df = df.applymap(lambda x: mapping[x] if x in mapping_keys else x)\n",
        "    df.to_csv(output_file, index=False)\n",
        "\n",
        "    print(f\"✅ De-anonymized file saved as {output_file}\")\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------\n",
        "#function to determine whcih type of data is need to perform\n",
        "#--------------------------------------------------------------\n",
        "def anonymization(input_file):\n",
        "    if input_file.endswith(\".csv\"):\n",
        "        csv_an(input_file,\"intermediate.csv\")\n",
        "        csv_dean(\"intermediate.csv\",\"deanonymized.csv\",\"mappings.json\")\n",
        "    elif input_file.endswith(\".xlsx\"):\n",
        "        excel_an(input_file,\"intermediate.xlsx\")\n",
        "        excel_dean(\"intermediate.xlsx\",\"deanonymized.xlsx\",\"mappings.json\")\n",
        "\n"
      ],
      "metadata": {
        "id": "1bSCFFxznhj5",
        "outputId": "b7cf536e-c858-487f-edea-74e264001f3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file=\"numerical.csv\"\n",
        "anonymization(file)"
      ],
      "metadata": {
        "id": "mDhYiVpaRWRa",
        "outputId": "36eddb23-13dd-40c6-828a-cc8131c46161",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Anonymized file saved as intermediate.csv\n",
            "🔄 Loading data...\n",
            "✅ De-anonymized file saved as deanonymized.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-f886e055ff3f>:243: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: mapping[x] if x in mapping_keys else x)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}